{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0fd016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from xgboost import XGBRegressor\n",
    "import pickle\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf109216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_DSL(path,feature,target): #here feature and target mean the indeces for feature and target\n",
    "    data_csv = pd.read_csv(path)\n",
    "    rbb = sklearn.utils.Bunch()\n",
    "    rbb.data = _get_rbbdata(data_csv,feature)\n",
    "    rbb.target = _get_rbbtarget(data_csv,target)\n",
    "    rbb.DESCR = _get_rbbdescr(data_csv)\n",
    "    rbb.feature_names = _get_feature_names(feature)\n",
    "    rbb.target_names = _get_target_names(target)\n",
    "\n",
    "    return rbb\n",
    "\n",
    "def _get_rbbdata(data,feature):\n",
    "    data_r = data.iloc[:, feature]\n",
    "    data_np = np.array(data_r)\n",
    "    return data_np\n",
    "\n",
    "\n",
    "def _get_rbbtarget(data,target):\n",
    "    data_b = data.iloc[:, target]\n",
    "    data_np = np.array(data_b)\n",
    "    return data_np\n",
    "\n",
    "\n",
    "def _get_rbbdescr(data):\n",
    "    text = \"\"\n",
    "    return text\n",
    "\n",
    "\n",
    "def _get_feature_names(feature):\n",
    "    data_csv = pd.read_csv(path)\n",
    "    fnames = data_csv.columns.values[feature].tolist()\n",
    "    return fnames\n",
    "\n",
    "\n",
    "def _get_target_names(target):\n",
    "    data_csv = pd.read_csv(path)\n",
    "    tnames = data_csv.columns.values[target]\n",
    "    return tnames\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f95738",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "286b8026",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a22e6f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data\n",
    "model_name=\"3\"\n",
    "feature=list(range(11,11+5))\n",
    "\n",
    "pressure=np.log10([0.001,0.002,0.005,0.01,0.02,0.05,0.1,0.2,0.5,1.0])\n",
    "mydatabase=load_DSL(path,feature,[1,2,3,4,5,6,7,8,9,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce8a06d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer = StandardScaler()\n",
    "x_train = mydatabase.data\n",
    "x_train_scaled = transfer.fit_transform(x_train)\n",
    "joblib.dump(transfer, \"scaler_\"+model_name+'.pkl') \n",
    "y_train = mydatabase.target\n",
    "estimator = XGBRegressor(n_estimators=2000, learning_rate=0.05, random_state=42)\n",
    "estimator.fit(x_train_scaled,y_train)\n",
    "joblib.dump(estimator, \"model_\"+model_name+'.pkl')\n",
    "np.savetxt(\"x_train_\"+model_name+\".txt\",x_train)\n",
    "np.savetxt(\"x_name_\"+model_name+\".txt\",mydatabase.feature_names,fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69feb2c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
